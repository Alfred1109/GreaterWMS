from django.core.management.base import BaseCommand
from django.conf import settings
from django.core.mail import send_mail
import os
import shutil
import sqlite3
import hashlib
import json
import logging
from datetime import datetime, timedelta
from pathlib import Path
import subprocess
import gzip

logger = logging.getLogger(__name__)

class Command(BaseCommand):
    help = 'GreaterWMSæ•°æ®åº“å¤‡ä»½ç®¡ç†å‘½ä»¤'

    def add_arguments(self, parser):
        parser.add_argument(
            '--type',
            type=str,
            choices=['full', 'incremental', 'hot'],
            default='full',
            help='å¤‡ä»½ç±»å‹: full(å…¨é‡), incremental(å¢é‡), hot(çƒ­å¤‡ä»½)'
        )
        parser.add_argument(
            '--cleanup',
            action='store_true',
            help='æ¸…ç†è¿‡æœŸå¤‡ä»½æ–‡ä»¶'
        )
        parser.add_argument(
            '--verify',
            type=str,
            help='éªŒè¯æŒ‡å®šå¤‡ä»½æ–‡ä»¶çš„å®Œæ•´æ€§'
        )
        parser.add_argument(
            '--compress',
            action='store_true',
            help='å‹ç¼©å¤‡ä»½æ–‡ä»¶'
        )
        parser.add_argument(
            '--encrypt',
            action='store_true',
            help='åŠ å¯†å¤‡ä»½æ–‡ä»¶'
        )
        parser.add_argument(
            '--silent',
            action='store_true',
            help='é™é»˜æ¨¡å¼ï¼Œä¸è¾“å‡ºè¯¦ç»†ä¿¡æ¯'
        )

    def handle(self, *args, **options):
        self.options = options
        self.backup_base_dir = Path(settings.BASE_DIR) / 'backups'
        self.db_path = Path(settings.DATABASES['default']['NAME'])
        
        if not self.options['silent']:
            self.stdout.write(self.style.SUCCESS('ğŸ—„ï¸  GreaterWMS æ•°æ®åº“å¤‡ä»½å·¥å…·'))
            self.stdout.write("=" * 80)
            self.stdout.write(f"æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            self.stdout.write("=" * 80)

        # åˆ›å»ºå¤‡ä»½ç›®å½•ç»“æ„
        self.create_backup_directories()
        
        # è®¾ç½®æ—¥å¿—
        self.setup_logging()

        try:
            if options['cleanup']:
                self.cleanup_old_backups()
            elif options['verify']:
                self.verify_backup(options['verify'])
            else:
                # æ‰§è¡Œå¤‡ä»½æ“ä½œ
                self.perform_backup(options['type'])
        except Exception as e:
            self.handle_error(f"å¤‡ä»½æ“ä½œå¤±è´¥: {str(e)}")

    def create_backup_directories(self):
        """åˆ›å»ºå¤‡ä»½ç›®å½•ç»“æ„"""
        directories = ['full', 'incremental', 'hot', 'logs']
        for dir_name in directories:
            dir_path = self.backup_base_dir / dir_name
            dir_path.mkdir(parents=True, exist_ok=True)
            # è®¾ç½®ç›®å½•æƒé™
            os.chmod(str(dir_path), 0o700)

    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—é…ç½®"""
        log_file = self.backup_base_dir / 'logs' / 'backup.log'
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(str(log_file)),
                logging.StreamHandler() if not self.options['silent'] else logging.NullHandler()
            ]
        )

    def perform_backup(self, backup_type):
        """æ‰§è¡Œå¤‡ä»½æ“ä½œ"""
        if not self.db_path.exists():
            raise FileNotFoundError(f"æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {self.db_path}")

        # ç”Ÿæˆå¤‡ä»½æ–‡ä»¶å
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_filename = f"{backup_type}_backup_{timestamp}.sqlite3"
        
        # ç¡®å®šå¤‡ä»½ç›®å½•
        backup_dir = self.backup_base_dir / backup_type
        backup_file_path = backup_dir / backup_filename

        self.stdout.write(f"\nğŸ“‹ æ‰§è¡Œ{backup_type}å¤‡ä»½...")
        self.stdout.write(f"æºæ–‡ä»¶: {self.db_path}")
        self.stdout.write(f"ç›®æ ‡æ–‡ä»¶: {backup_file_path}")

        # æ£€æŸ¥ç£ç›˜ç©ºé—´
        if not self.check_disk_space():
            raise Exception("ç£ç›˜ç©ºé—´ä¸è¶³ï¼Œæ— æ³•æ‰§è¡Œå¤‡ä»½")

        # æ‰§è¡Œå¤‡ä»½
        start_time = datetime.now()
        
        if backup_type == 'hot':
            self.perform_hot_backup(backup_file_path)
        else:
            self.perform_cold_backup(backup_file_path)

        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()

        # è®¾ç½®æ–‡ä»¶æƒé™
        os.chmod(str(backup_file_path), 0o600)

        # éªŒè¯å¤‡ä»½
        if self.verify_backup_integrity(backup_file_path):
            self.stdout.write(self.style.SUCCESS(f"âœ… å¤‡ä»½æˆåŠŸå®Œæˆ"))
        else:
            raise Exception("å¤‡ä»½æ–‡ä»¶éªŒè¯å¤±è´¥")

        # å‹ç¼©å¤‡ä»½æ–‡ä»¶ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if self.options['compress']:
            compressed_file = self.compress_backup(backup_file_path)
            self.stdout.write(f"ğŸ—œï¸  å·²å‹ç¼©: {compressed_file}")

        # åŠ å¯†å¤‡ä»½æ–‡ä»¶ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if self.options['encrypt']:
            encrypted_file = self.encrypt_backup(backup_file_path)
            self.stdout.write(f"ğŸ” å·²åŠ å¯†: {encrypted_file}")

        # è®°å½•å¤‡ä»½ä¿¡æ¯
        self.record_backup_info(backup_file_path, backup_type, duration)

        # å‘é€é€šçŸ¥ï¼ˆå¦‚æœé…ç½®äº†é‚®ä»¶ï¼‰
        self.send_notification(backup_file_path, backup_type, True)

        self.stdout.write(f"â±ï¸  å¤‡ä»½è€—æ—¶: {duration:.2f}ç§’")
        logger.info(f"å¤‡ä»½å®Œæˆ: {backup_file_path}, è€—æ—¶: {duration:.2f}ç§’")

    def perform_hot_backup(self, backup_file_path):
        """æ‰§è¡Œçƒ­å¤‡ä»½ï¼ˆåœ¨çº¿å¤‡ä»½ï¼‰"""
        try:
            # ä½¿ç”¨SQLiteçš„åœ¨çº¿å¤‡ä»½API
            source_conn = sqlite3.connect(str(self.db_path))
            backup_conn = sqlite3.connect(str(backup_file_path))
            
            # æ‰§è¡Œåœ¨çº¿å¤‡ä»½
            source_conn.backup(backup_conn)
            
            source_conn.close()
            backup_conn.close()
            
            self.stdout.write("ğŸ”¥ çƒ­å¤‡ä»½å®Œæˆï¼ˆæ•°æ®åº“æ— éœ€åœæœºï¼‰")
            
        except Exception as e:
            raise Exception(f"çƒ­å¤‡ä»½å¤±è´¥: {str(e)}")

    def perform_cold_backup(self, backup_file_path):
        """æ‰§è¡Œå†·å¤‡ä»½ï¼ˆæ–‡ä»¶å¤åˆ¶ï¼‰"""
        try:
            # ç®€å•çš„æ–‡ä»¶å¤åˆ¶
            shutil.copy2(str(self.db_path), str(backup_file_path))
            self.stdout.write("â„ï¸  å†·å¤‡ä»½å®Œæˆï¼ˆæ–‡ä»¶å¤åˆ¶ï¼‰")
            
        except Exception as e:
            raise Exception(f"å†·å¤‡ä»½å¤±è´¥: {str(e)}")

    def check_disk_space(self):
        """æ£€æŸ¥ç£ç›˜ç©ºé—´æ˜¯å¦è¶³å¤Ÿ"""
        db_size = self.db_path.stat().st_size
        backup_dir_stat = os.statvfs(str(self.backup_base_dir))
        free_space = backup_dir_stat.f_bavail * backup_dir_stat.f_frsize
        
        # éœ€è¦è‡³å°‘2å€çš„æ•°æ®åº“å¤§å°ç©ºé—´
        required_space = db_size * 2
        
        if free_space < required_space:
            self.stdout.write(self.style.ERROR(
                f"âš ï¸  ç£ç›˜ç©ºé—´ä¸è¶³: éœ€è¦{required_space/1024/1024:.2f}MBï¼Œå¯ç”¨{free_space/1024/1024:.2f}MB"
            ))
            return False
        
        return True

    def verify_backup_integrity(self, backup_file_path):
        """éªŒè¯å¤‡ä»½æ–‡ä»¶å®Œæ•´æ€§"""
        try:
            # è®¡ç®—æ–‡ä»¶å“ˆå¸Œå€¼
            original_hash = self.calculate_file_hash(str(self.db_path))
            backup_hash = self.calculate_file_hash(str(backup_file_path))
            
            # éªŒè¯SQLiteæ•°æ®åº“å®Œæ•´æ€§
            conn = sqlite3.connect(str(backup_file_path))
            cursor = conn.cursor()
            cursor.execute("PRAGMA integrity_check")
            result = cursor.fetchone()
            conn.close()
            
            if result[0] != 'ok':
                self.stdout.write(self.style.ERROR(f"âŒ æ•°æ®åº“å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥: {result[0]}"))
                return False
            
            # å¯¹äºå†·å¤‡ä»½ï¼Œå“ˆå¸Œå€¼åº”è¯¥ç›¸åŒ
            if original_hash == backup_hash:
                self.stdout.write("âœ… å¤‡ä»½æ–‡ä»¶å®Œæ•´æ€§éªŒè¯é€šè¿‡")
                return True
            else:
                # å¯¹äºçƒ­å¤‡ä»½ï¼Œç”±äºå¯èƒ½æœ‰å¹¶å‘å†™å…¥ï¼Œå…è®¸å“ˆå¸Œå€¼ä¸åŒ
                self.stdout.write("âš ï¸  å¤‡ä»½æ–‡ä»¶å“ˆå¸Œå€¼ä¸åŒï¼ˆçƒ­å¤‡ä»½æ­£å¸¸ç°è±¡ï¼‰")
                return True
                
        except Exception as e:
            self.stdout.write(self.style.ERROR(f"âŒ å®Œæ•´æ€§éªŒè¯å¤±è´¥: {str(e)}"))
            return False

    def calculate_file_hash(self, file_path):
        """è®¡ç®—æ–‡ä»¶MD5å“ˆå¸Œå€¼"""
        hash_md5 = hashlib.md5()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()

    def compress_backup(self, backup_file_path):
        """å‹ç¼©å¤‡ä»½æ–‡ä»¶"""
        compressed_path = Path(str(backup_file_path) + '.gz')
        
        with open(backup_file_path, 'rb') as f_in:
            with gzip.open(compressed_path, 'wb') as f_out:
                shutil.copyfileobj(f_in, f_out)
        
        # åˆ é™¤åŸå§‹å¤‡ä»½æ–‡ä»¶
        backup_file_path.unlink()
        return compressed_path

    def encrypt_backup(self, backup_file_path):
        """åŠ å¯†å¤‡ä»½æ–‡ä»¶ï¼ˆç®€å•ç¤ºä¾‹ï¼Œç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨æ›´å¼ºçš„åŠ å¯†ï¼‰"""
        # è¿™é‡Œåªæ˜¯ç¤ºä¾‹ï¼Œå®é™…åº”ç”¨ä¸­åº”ä½¿ç”¨æ›´å®‰å…¨çš„åŠ å¯†æ–¹æ³•
        encrypted_path = Path(str(backup_file_path) + '.enc')
        
        # ç®€å•çš„XORåŠ å¯†ç¤ºä¾‹ï¼ˆä¸æ¨èç”¨äºç”Ÿäº§ï¼‰
        key = b'GreaterWMS-Backup-Key-2024'
        
        with open(backup_file_path, 'rb') as f_in:
            with open(encrypted_path, 'wb') as f_out:
                data = f_in.read()
                encrypted_data = bytes(a ^ b for a, b in zip(data, (key * (len(data) // len(key) + 1))[:len(data)]))
                f_out.write(encrypted_data)
        
        # åˆ é™¤åŸå§‹å¤‡ä»½æ–‡ä»¶
        backup_file_path.unlink()
        return encrypted_path

    def record_backup_info(self, backup_file_path, backup_type, duration):
        """è®°å½•å¤‡ä»½ä¿¡æ¯"""
        info = {
            'timestamp': datetime.now().isoformat(),
            'backup_type': backup_type,
            'file_path': str(backup_file_path),
            'file_size': backup_file_path.stat().st_size,
            'duration': duration,
            'hash': self.calculate_file_hash(str(backup_file_path)),
            'compressed': self.options['compress'],
            'encrypted': self.options['encrypt']
        }
        
        info_file = self.backup_base_dir / 'logs' / f"backup_info_{backup_type}.json"
        
        # è¯»å–ç°æœ‰ä¿¡æ¯
        backups_info = []
        if info_file.exists():
            with open(info_file, 'r', encoding='utf-8') as f:
                backups_info = json.load(f)
        
        # æ·»åŠ æ–°ä¿¡æ¯
        backups_info.append(info)
        
        # ä¿å­˜ä¿¡æ¯
        with open(info_file, 'w', encoding='utf-8') as f:
            json.dump(backups_info, f, ensure_ascii=False, indent=2)

    def cleanup_old_backups(self):
        """æ¸…ç†è¿‡æœŸå¤‡ä»½æ–‡ä»¶"""
        self.stdout.write("\nğŸ§¹ æ¸…ç†è¿‡æœŸå¤‡ä»½æ–‡ä»¶...")
        
        retention_policies = {
            'full': 30,  # å…¨é‡å¤‡ä»½ä¿ç•™30å¤©
            'incremental': 7,  # å¢é‡å¤‡ä»½ä¿ç•™7å¤©
            'hot': 3  # çƒ­å¤‡ä»½ä¿ç•™3å¤©
        }
        
        total_cleaned = 0
        total_size_freed = 0
        
        for backup_type, retention_days in retention_policies.items():
            backup_dir = self.backup_base_dir / backup_type
            cutoff_date = datetime.now() - timedelta(days=retention_days)
            
            if not backup_dir.exists():
                continue
                
            cleaned_count = 0
            size_freed = 0
            
            for backup_file in backup_dir.glob('*_backup_*.sqlite3*'):
                try:
                    # ä»æ–‡ä»¶åæå–æ—¶é—´æˆ³
                    timestamp_str = backup_file.stem.split('_')[-2] + '_' + backup_file.stem.split('_')[-1]
                    if backup_file.suffix == '.gz':
                        timestamp_str = backup_file.stem.replace('.sqlite3', '').split('_')[-2] + '_' + \
                                       backup_file.stem.replace('.sqlite3', '').split('_')[-1]
                    
                    file_date = datetime.strptime(timestamp_str, '%Y%m%d_%H%M%S')
                    
                    if file_date < cutoff_date:
                        file_size = backup_file.stat().st_size
                        backup_file.unlink()
                        cleaned_count += 1
                        size_freed += file_size
                        self.stdout.write(f"  ğŸ—‘ï¸  å·²åˆ é™¤: {backup_file.name}")
                        
                except (ValueError, IndexError) as e:
                    self.stdout.write(f"  âš ï¸  æ— æ³•è§£ææ–‡ä»¶æ—¶é—´æˆ³: {backup_file.name}")
                    continue
            
            if cleaned_count > 0:
                self.stdout.write(f"ğŸ“ {backup_type}å¤‡ä»½: æ¸…ç†äº†{cleaned_count}ä¸ªæ–‡ä»¶ï¼Œé‡Šæ”¾{size_freed/1024/1024:.2f}MBç©ºé—´")
            
            total_cleaned += cleaned_count
            total_size_freed += size_freed
        
        if total_cleaned > 0:
            self.stdout.write(self.style.SUCCESS(
                f"âœ… æ¸…ç†å®Œæˆ: æ€»å…±åˆ é™¤{total_cleaned}ä¸ªæ–‡ä»¶ï¼Œé‡Šæ”¾{total_size_freed/1024/1024:.2f}MBç©ºé—´"
            ))
        else:
            self.stdout.write("â„¹ï¸  æ²¡æœ‰è¿‡æœŸå¤‡ä»½éœ€è¦æ¸…ç†")

    def verify_backup(self, backup_file):
        """éªŒè¯æŒ‡å®šçš„å¤‡ä»½æ–‡ä»¶"""
        backup_path = Path(backup_file)
        
        if not backup_path.exists():
            self.stdout.write(self.style.ERROR(f"âŒ å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨: {backup_file}"))
            return
        
        self.stdout.write(f"\nğŸ” éªŒè¯å¤‡ä»½æ–‡ä»¶: {backup_path.name}")
        
        try:
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = backup_path.stat().st_size
            self.stdout.write(f"ğŸ“ æ–‡ä»¶å¤§å°: {file_size/1024/1024:.2f}MB")
            
            # éªŒè¯SQLiteæ•°æ®åº“
            conn = sqlite3.connect(str(backup_path))
            cursor = conn.cursor()
            
            # å®Œæ•´æ€§æ£€æŸ¥
            cursor.execute("PRAGMA integrity_check")
            integrity_result = cursor.fetchone()
            
            if integrity_result[0] == 'ok':
                self.stdout.write("âœ… æ•°æ®åº“å®Œæ•´æ€§æ£€æŸ¥é€šè¿‡")
            else:
                self.stdout.write(self.style.ERROR(f"âŒ æ•°æ®åº“å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥: {integrity_result[0]}"))
                return
            
            # ç»Ÿè®¡è¡¨æ•°é‡
            cursor.execute("SELECT COUNT(*) FROM sqlite_master WHERE type='table'")
            table_count = cursor.fetchone()[0]
            self.stdout.write(f"ğŸ“Š æ•°æ®è¡¨æ•°é‡: {table_count}")
            
            # è®¡ç®—æ€»è®°å½•æ•°ï¼ˆç¤ºä¾‹ï¼‰
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%'")
            tables = cursor.fetchall()
            
            total_records = 0
            for table in tables[:5]:  # åªæ£€æŸ¥å‰5ä¸ªè¡¨ï¼Œé¿å…å¤ªæ…¢
                try:
                    cursor.execute(f"SELECT COUNT(*) FROM `{table[0]}`")
                    count = cursor.fetchone()[0]
                    total_records += count
                    self.stdout.write(f"  ğŸ“‹ {table[0]}: {count}æ¡è®°å½•")
                except Exception as e:
                    self.stdout.write(f"  âš ï¸  {table[0]}: æ— æ³•ç»Ÿè®¡è®°å½•æ•°")
            
            if len(tables) > 5:
                self.stdout.write(f"  ... è¿˜æœ‰{len(tables) - 5}ä¸ªè¡¨æœªæ˜¾ç¤º")
            
            conn.close()
            
            # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
            file_hash = self.calculate_file_hash(str(backup_path))
            self.stdout.write(f"ğŸ” æ–‡ä»¶å“ˆå¸Œ: {file_hash}")
            
            self.stdout.write(self.style.SUCCESS("âœ… å¤‡ä»½æ–‡ä»¶éªŒè¯å®Œæˆ"))
            
        except Exception as e:
            self.stdout.write(self.style.ERROR(f"âŒ éªŒè¯å¤±è´¥: {str(e)}"))

    def send_notification(self, backup_file_path, backup_type, success):
        """å‘é€å¤‡ä»½é€šçŸ¥é‚®ä»¶"""
        if not hasattr(settings, 'EMAIL_HOST') or not hasattr(settings, 'BACKUP_ALERT_EMAILS'):
            return
        
        subject = f"GreaterWMS æ•°æ®åº“å¤‡ä»½{'æˆåŠŸ' if success else 'å¤±è´¥'}"
        
        if success:
            message = f"""
æ•°æ®åº“å¤‡ä»½æˆåŠŸå®Œæˆ

å¤‡ä»½ç±»å‹: {backup_type}
å¤‡ä»½æ–‡ä»¶: {backup_file_path.name}
æ–‡ä»¶å¤§å°: {backup_file_path.stat().st_size / 1024 / 1024:.2f}MB
å¤‡ä»½æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ç³»ç»Ÿè¿è¡Œæ­£å¸¸ã€‚
            """
        else:
            message = f"""
æ•°æ®åº“å¤‡ä»½æ‰§è¡Œå¤±è´¥

å¤‡ä»½ç±»å‹: {backup_type}
å¤±è´¥æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

è¯·æ£€æŸ¥ç³»ç»ŸçŠ¶æ€å¹¶åŠæ—¶å¤„ç†ã€‚
            """
        
        try:
            send_mail(
                subject,
                message,
                settings.EMAIL_HOST_USER,
                settings.BACKUP_ALERT_EMAILS,
                fail_silently=False,
            )
            if not self.options['silent']:
                self.stdout.write("ğŸ“§ å·²å‘é€å¤‡ä»½é€šçŸ¥é‚®ä»¶")
        except Exception as e:
            if not self.options['silent']:
                self.stdout.write(f"âš ï¸  é‚®ä»¶å‘é€å¤±è´¥: {str(e)}")

    def handle_error(self, error_message):
        """å¤„ç†é”™è¯¯"""
        self.stdout.write(self.style.ERROR(error_message))
        logger.error(error_message)
        
        # å‘é€é”™è¯¯é€šçŸ¥
        self.send_notification(Path(""), "unknown", False)
        
        raise Exception(error_message)
